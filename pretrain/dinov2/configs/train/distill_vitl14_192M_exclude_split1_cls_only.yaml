
distill:
  loss_name: kldiv  # KLDIV, RADIO
  UNI_loss_ratio: 1
  UNI_patch_ratio: 0
  Phikon_loss_ratio: 0
  Phikon_patch_ratio: 0
  CONCH_loss_ratio: 1
  CONCH_patch_ratio: 0

train:
  batch_size_per_gpu: 96
  dataset_path: Pathology:root=/scratch/vcompath/exclude_split1_dict.json
  # centering: sinkhorn_knopp
student:
  arch: vit_large
  pretrained_weights: /project/vcompath/storage/Pathology/result/distill_vitl14_192M_exclude_split1/eval/training_99999/teacher_checkpoint.pth
  patch_size: 14
  drop_path_rate: 0.4
  ffn_layer: mlp
  block_chunks: 4
teacher:
  momentum_teacher: 0.992
optim:
  epochs: 400
  base_lr: 0.0004  # learning rate for a batch size of 1024
  warmup_epochs: 40
crops:
  local_crops_size: 98